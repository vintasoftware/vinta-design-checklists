## Checklist Objective
#### This checklist is meant to be used by product designers while setting up and executing an usability test with a prototype, with people around the office. The test should be quick and not involve too much effort on the designer’s part.

**Disclaimer**: Running in-house usability tests shouldn’t replace structured research (tests, interviews, surveys) with real users. The main goal of this practice is to help designers catch the more critical problems in their interfaces before working on a more elaborate version of the solution, or put some risky design ideas up for validation with your team.

## 1. Test setup
* [ ] Have your prototype ready. 
    * Perform a quick dry-run to see if every hotspot is working as intended, catch any technical glitches, and check if all the interactive elements that the UI needs are enabled.
* [ ] Enlist people from different projects to test your UI.
* [ ] Book a room, and set aside enough time to test the UI with five people, one at a time.
    * For small features, 10 minutes per participant is enough. 
* [ ] Set aside some time to consolidate your insights after the test, about 5 minutes for each participant.

## 2. Running the test
* [ ] Preferably let participants use their own devices (smartphones or computers). 
* [ ] Explain briefly what the feature is about, and ask them to perform one specific action.
* [ ] Ask them to "think aloud" as they interact with your prototype.
* [ ] If the participant struggles with interaction, don't explain why you designed it that way. Focus on collecting useful insights. 
* [ ] After participants are done, ask them for feedback related to the feature. Let them speak freely and be careful with biasing them for a specific answer.

## 3. Evaluating the results
* [ ] Analyze the results right after the test, for each participant. Do it while the memories are fresh in your mind. Use this template to help you track all your insights.
* [ ] Answer the following questions about the feature you just tested:
*    [ ] Do the users understand the task they're supposed to perform?
*    [ ] Are the visual signifiers (buttons, selectors, checkboxes, links) clear enough?
*    [ ] Are users going through the predicted path?
*    [ ] Are the components finger-friendly (in the case of mobile views)?
*    [ ] Are users performing the task successfully?
* [ ] After the round of tests, go back to your design tools and improve the solution based on participants' feedback.

## 4. Follow-up
* [ ] When you finish working on the feature, let your test participants know what has improved and how helpful they were on your process.
